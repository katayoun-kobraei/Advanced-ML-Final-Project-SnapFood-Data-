{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7436959,"sourceType":"datasetVersion","datasetId":4318397}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install hazm","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:40:26.771463Z","iopub.execute_input":"2024-01-30T06:40:26.771833Z","iopub.status.idle":"2024-01-30T06:40:44.073959Z","shell.execute_reply.started":"2024-01-30T06:40:26.771806Z","shell.execute_reply":"2024-01-30T06:40:44.072737Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting hazm\n  Obtaining dependency information for hazm from https://files.pythonhosted.org/packages/91/8c/cc3d01c27681eb8223781ea162a23f9926647ce864eb601a19aee4bce0af/hazm-0.10.0-py3-none-any.whl.metadata\n  Downloading hazm-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: flashtext<3.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from hazm) (2.7)\nRequirement already satisfied: gensim<5.0.0,>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from hazm) (4.3.2)\nCollecting nltk<4.0.0,>=3.8.1 (from hazm)\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy==1.24.3 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.24.3)\nCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n  Obtaining dependency information for python-crfsuite<0.10.0,>=0.9.9 from https://files.pythonhosted.org/packages/38/1d/c475ba7d11e9735f00eb08e2f5315aa2e21c24cc85a0474c3fd425edef58/python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.2.2)\nRequirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.11.1)\nRequirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (68.1.2)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.11.4)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.3.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2023.8.8)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.2.0)\nDownloading hazm-0.10.0-py3-none-any.whl (892 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, nltk, fasttext-wheel, hazm\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 hazm-0.10.0 nltk-3.8.1 python-crfsuite-0.9.10\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install urlextract","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:40:44.076318Z","iopub.execute_input":"2024-01-30T06:40:44.076658Z","iopub.status.idle":"2024-01-30T06:40:58.197356Z","shell.execute_reply.started":"2024-01-30T06:40:44.076630Z","shell.execute_reply":"2024-01-30T06:40:58.196061Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting urlextract\n  Downloading urlextract-1.8.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from urlextract) (3.4)\nCollecting uritools (from urlextract)\n  Obtaining dependency information for uritools from https://files.pythonhosted.org/packages/6b/ff/b16f225ceeb47f5d8899371ce446a8d6c1fe509a8882998b869f2a794c25/uritools-4.0.2-py3-none-any.whl.metadata\n  Downloading uritools-4.0.2-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from urlextract) (4.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from urlextract) (3.12.2)\nDownloading uritools-4.0.2-py3-none-any.whl (10 kB)\nInstalling collected packages: uritools, urlextract\nSuccessfully installed uritools-4.0.2 urlextract-1.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install emojis","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:40:58.198962Z","iopub.execute_input":"2024-01-30T06:40:58.199338Z","iopub.status.idle":"2024-01-30T06:41:11.811353Z","shell.execute_reply.started":"2024-01-30T06:40:58.199308Z","shell.execute_reply":"2024-01-30T06:41:11.810239Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting emojis\n  Downloading emojis-0.7.0-py3-none-any.whl (28 kB)\nInstalling collected packages: emojis\nSuccessfully installed emojis-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tokenizers","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:11.814003Z","iopub.execute_input":"2024-01-30T06:41:11.814421Z","iopub.status.idle":"2024-01-30T06:41:25.137725Z","shell.execute_reply.started":"2024-01-30T06:41:11.814391Z","shell.execute_reply":"2024-01-30T06:41:25.136465Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.15.0)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers) (0.20.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import unicode_literals\nfrom hazm import *\nimport tensorflow as tf\nfrom keras.models import Sequential\nimport pandas as pd\nfrom keras.layers import Dense\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tokenizers import Tokenizer, models, trainers, processors\nimport re\nfrom urlextract import URLExtract\nimport emojis\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import Adadelta,Adam,RMSprop\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom keras.optimizers import Adadelta,Adam,RMSprop\nfrom tensorflow.keras import layers\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:25.139413Z","iopub.execute_input":"2024-01-30T06:41:25.139761Z","iopub.status.idle":"2024-01-30T06:41:48.076159Z","shell.execute_reply.started":"2024-01-30T06:41:25.139729Z","shell.execute_reply":"2024-01-30T06:41:48.075121Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/snapfood-reveiews/snappfood_comments_preprocessed (2).csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:48.077476Z","iopub.execute_input":"2024-01-30T06:41:48.078169Z","iopub.status.idle":"2024-01-30T06:41:48.996008Z","shell.execute_reply.started":"2024-01-30T06:41:48.078139Z","shell.execute_reply":"2024-01-30T06:41:48.995173Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data['Cleaned']","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:48.997300Z","iopub.execute_input":"2024-01-30T06:41:48.997653Z","iopub.status.idle":"2024-01-30T06:41:49.011557Z","shell.execute_reply.started":"2024-01-30T06:41:48.997624Z","shell.execute_reply":"2024-01-30T06:41:49.010516Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0          واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح\n1        قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...\n2        قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...\n3        عالی بود همه چه درست و به اندازه و کیفیت خوب ا...\n4                            شیرینی وانیلی فقط یک مدل بود \n                               ...                        \n56695    یک تیکه کم فرستاده بودن و با تماس من در کمترین...\n56696    عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...\n56697    مثل همیشه عالی من چندمین باره سفارش میدم و هرب...\n56698        دلستر استوایی خواسته بودم اما لیمویی فرستادند\n56699    جای مرغ گریل شده ناگت بود به این نمی‌گن چیکن ب...\nName: Cleaned, Length: 56700, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:49.012893Z","iopub.execute_input":"2024-01-30T06:41:49.013243Z","iopub.status.idle":"2024-01-30T06:41:49.033473Z","shell.execute_reply.started":"2024-01-30T06:41:49.013216Z","shell.execute_reply":"2024-01-30T06:41:49.032465Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                            comment  label  \\\n0           0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح    SAD   \n1           1  قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...  HAPPY   \n2           2  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...    SAD   \n3           3  عالللی بود همه چه درست و به اندازه و کیفیت خوب...  HAPPY   \n4           4                      شیرینی وانیلی فقط یک مدل بود.  HAPPY   \n\n   label_id                                            Cleaned  \\\n0         1    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح   \n1         0  قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...   \n2         1  قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...   \n3         0  عالی بود همه چه درست و به اندازه و کیفیت خوب ا...   \n4         0                      شیرینی وانیلی فقط یک مدل بود    \n\n                                     Cleaned_sw_rmvd  \n0       واقعا حیف وقت بنویسم سرویس دهیتون شده افتضاح  \n1  قرار بود 1 ساعته برسه نیم ساعت زودتر موقع رسید...  \n2  قیمت مدل اصلا کیفیتش سازگاری نداره فقط ظاهر فر...  \n3  عالی بود درست اندازه کیفیت خوب امیداورم همیشه ...  \n4                          شیرینی وانیلی فقط مدل بود  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>comment</th>\n      <th>label</th>\n      <th>label_id</th>\n      <th>Cleaned</th>\n      <th>Cleaned_sw_rmvd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n      <td>SAD</td>\n      <td>1</td>\n      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n      <td>واقعا حیف وقت بنویسم سرویس دهیتون شده افتضاح</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n      <td>قرار بود 1 ساعته برسه نیم ساعت زودتر موقع رسید...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n      <td>SAD</td>\n      <td>1</td>\n      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...</td>\n      <td>قیمت مدل اصلا کیفیتش سازگاری نداره فقط ظاهر فر...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>عالللی بود همه چه درست و به اندازه و کیفیت خوب...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب ا...</td>\n      <td>عالی بود درست اندازه کیفیت خوب امیداورم همیشه ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>شیرینی وانیلی فقط یک مدل بود</td>\n      <td>شیرینی وانیلی فقط مدل بود</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = data.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:49.036074Z","iopub.execute_input":"2024-01-30T06:41:49.036796Z","iopub.status.idle":"2024-01-30T06:41:49.080914Z","shell.execute_reply.started":"2024-01-30T06:41:49.036767Z","shell.execute_reply":"2024-01-30T06:41:49.079791Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"labels = data['label_id'].values","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:49.084290Z","iopub.execute_input":"2024-01-30T06:41:49.084609Z","iopub.status.idle":"2024-01-30T06:41:49.089031Z","shell.execute_reply.started":"2024-01-30T06:41:49.084584Z","shell.execute_reply":"2024-01-30T06:41:49.088061Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:41:49.090254Z","iopub.execute_input":"2024-01-30T06:41:49.090538Z","iopub.status.idle":"2024-01-30T06:41:49.111457Z","shell.execute_reply.started":"2024-01-30T06:41:49.090514Z","shell.execute_reply":"2024-01-30T06:41:49.110388Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0                                            comment  label  \\\n0               0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح    SAD   \n1               1  قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...  HAPPY   \n2               2  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...    SAD   \n3               3  عالللی بود همه چه درست و به اندازه و کیفیت خوب...  HAPPY   \n4               4                      شیرینی وانیلی فقط یک مدل بود.  HAPPY   \n...           ...                                                ...    ...   \n56695       56695  یک تیکه کم فرستاده بودن و با تماس من در کمترین...  HAPPY   \n56696       56696  عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...  HAPPY   \n56697       56697  مثل همیشه عالی، من چندمین باره سفارش میدم و هر...  HAPPY   \n56698       56698      دلستر استوایی خواسته بودم اما لیمویی فرستادند  HAPPY   \n56699       56699  جای مرغ گریل شده ناگت بود، به این نمی‌گن چیکن ...    SAD   \n\n       label_id                                            Cleaned  \\\n0             1    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح   \n1             0  قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...   \n2             1  قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...   \n3             0  عالی بود همه چه درست و به اندازه و کیفیت خوب ا...   \n4             0                      شیرینی وانیلی فقط یک مدل بود    \n...         ...                                                ...   \n56695         0  یک تیکه کم فرستاده بودن و با تماس من در کمترین...   \n56696         0  عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...   \n56697         0  مثل همیشه عالی من چندمین باره سفارش میدم و هرب...   \n56698         0      دلستر استوایی خواسته بودم اما لیمویی فرستادند   \n56699         1  جای مرغ گریل شده ناگت بود به این نمی‌گن چیکن ب...   \n\n                                         Cleaned_sw_rmvd  \n0           واقعا حیف وقت بنویسم سرویس دهیتون شده افتضاح  \n1      قرار بود 1 ساعته برسه نیم ساعت زودتر موقع رسید...  \n2      قیمت مدل اصلا کیفیتش سازگاری نداره فقط ظاهر فر...  \n3      عالی بود درست اندازه کیفیت خوب امیداورم همیشه ...  \n4                              شیرینی وانیلی فقط مدل بود  \n...                                                  ...  \n56695  تیکه کم فرستاده بودن تماس من کمترین زمان برام ...  \n56696     عالی بود چیز ممنونم پیک هم خیلی مرتب موقع آورد  \n56697  مثل همیشه عالی من چندمین باره سفارش میدم هربار...  \n56698          دلستر استوایی خواسته بودم لیمویی فرستادند  \n56699         جای مرغ گریل شده ناگت بود نمی‌گن چیکن برگر  \n\n[56498 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>comment</th>\n      <th>label</th>\n      <th>label_id</th>\n      <th>Cleaned</th>\n      <th>Cleaned_sw_rmvd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n      <td>SAD</td>\n      <td>1</td>\n      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n      <td>واقعا حیف وقت بنویسم سرویس دهیتون شده افتضاح</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n      <td>قرار بود 1 ساعته برسه نیم ساعت زودتر موقع رسید...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n      <td>SAD</td>\n      <td>1</td>\n      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...</td>\n      <td>قیمت مدل اصلا کیفیتش سازگاری نداره فقط ظاهر فر...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>عالللی بود همه چه درست و به اندازه و کیفیت خوب...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب ا...</td>\n      <td>عالی بود درست اندازه کیفیت خوب امیداورم همیشه ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>شیرینی وانیلی فقط یک مدل بود</td>\n      <td>شیرینی وانیلی فقط مدل بود</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>56695</th>\n      <td>56695</td>\n      <td>یک تیکه کم فرستاده بودن و با تماس من در کمترین...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>یک تیکه کم فرستاده بودن و با تماس من در کمترین...</td>\n      <td>تیکه کم فرستاده بودن تماس من کمترین زمان برام ...</td>\n    </tr>\n    <tr>\n      <th>56696</th>\n      <td>56696</td>\n      <td>عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...</td>\n      <td>عالی بود چیز ممنونم پیک هم خیلی مرتب موقع آورد</td>\n    </tr>\n    <tr>\n      <th>56697</th>\n      <td>56697</td>\n      <td>مثل همیشه عالی، من چندمین باره سفارش میدم و هر...</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>مثل همیشه عالی من چندمین باره سفارش میدم و هرب...</td>\n      <td>مثل همیشه عالی من چندمین باره سفارش میدم هربار...</td>\n    </tr>\n    <tr>\n      <th>56698</th>\n      <td>56698</td>\n      <td>دلستر استوایی خواسته بودم اما لیمویی فرستادند</td>\n      <td>HAPPY</td>\n      <td>0</td>\n      <td>دلستر استوایی خواسته بودم اما لیمویی فرستادند</td>\n      <td>دلستر استوایی خواسته بودم لیمویی فرستادند</td>\n    </tr>\n    <tr>\n      <th>56699</th>\n      <td>56699</td>\n      <td>جای مرغ گریل شده ناگت بود، به این نمی‌گن چیکن ...</td>\n      <td>SAD</td>\n      <td>1</td>\n      <td>جای مرغ گریل شده ناگت بود به این نمی‌گن چیکن ب...</td>\n      <td>جای مرغ گریل شده ناگت بود نمی‌گن چیکن برگر</td>\n    </tr>\n  </tbody>\n</table>\n<p>56498 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## countvectorizer","metadata":{}},{"cell_type":"code","source":"count_vectorizer = CountVectorizer()\nX_count_vectorized = count_vectorizer.fit_transform(data.Cleaned).todense()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:17:10.830997Z","iopub.execute_input":"2024-01-30T06:17:10.832083Z","iopub.status.idle":"2024-01-30T06:17:14.262146Z","shell.execute_reply.started":"2024-01-30T06:17:10.832041Z","shell.execute_reply":"2024-01-30T06:17:14.261228Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_count_vectorized, labels, test_size=0.2, random_state=42) ","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:17:14.263389Z","iopub.execute_input":"2024-01-30T06:17:14.263709Z","iopub.status.idle":"2024-01-30T06:17:20.294276Z","shell.execute_reply.started":"2024-01-30T06:17:14.263683Z","shell.execute_reply":"2024-01-30T06:17:20.293130Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=2, max_features= 10000)\nX_tfidf_vectorized = vectorizer.fit_transform(data.Cleaned).todense()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:21.020990Z","iopub.execute_input":"2024-01-30T06:44:21.021864Z","iopub.status.idle":"2024-01-30T06:44:25.567842Z","shell.execute_reply.started":"2024-01-30T06:44:21.021818Z","shell.execute_reply":"2024-01-30T06:44:25.566910Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf_vectorized, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:25.569480Z","iopub.execute_input":"2024-01-30T06:44:25.569841Z","iopub.status.idle":"2024-01-30T06:44:27.721677Z","shell.execute_reply.started":"2024-01-30T06:44:25.569812Z","shell.execute_reply":"2024-01-30T06:44:27.720776Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"input_dim = X_tfidf_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:27.722930Z","iopub.execute_input":"2024-01-30T06:44:27.723274Z","iopub.status.idle":"2024-01-30T06:44:27.727519Z","shell.execute_reply.started":"2024-01-30T06:44:27.723246Z","shell.execute_reply":"2024-01-30T06:44:27.726562Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(input_dim)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:27.729260Z","iopub.execute_input":"2024-01-30T06:44:27.729540Z","iopub.status.idle":"2024-01-30T06:44:27.740810Z","shell.execute_reply.started":"2024-01-30T06:44:27.729515Z","shell.execute_reply":"2024-01-30T06:44:27.739754Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(45198, 10000)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Byte pair encoding tokenizer","metadata":{}},{"cell_type":"code","source":"import re \nfrom collections import defaultdict \n\ndef get_stats(vocab): \n    \"\"\" \n    Given a vocabulary (dictionary mapping words to frequency counts), returns a \n    dictionary of tuples representing the frequency count of pairs of characters \n    in the vocabulary. \n    \"\"\"\n    pairs = defaultdict(int) \n    for word, freq in vocab.items(): \n        symbols = word.split() \n        for i in range(len(symbols)-1): \n            pairs[symbols[i],symbols[i+1]] += freq \n    return pairs \n\ndef merge_vocab(pair, v_in): \n    \"\"\" \n    Given a pair of characters and a vocabulary, returns a new vocabulary with the \n    pair of characters merged together wherever they appear. \n    \"\"\"\n    v_out = {} \n    bigram = re.escape(' '.join(pair)) \n    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)') \n    for word in v_in: \n        w_out = p.sub(''.join(pair), word) \n        v_out[w_out] = v_in[word] \n    return v_out \n\ndef get_vocab(data): \n    \"\"\" \n    Given a list of strings, returns a dictionary of words mapping to their frequency \n    count in the data. \n    \"\"\"\n    vocab = defaultdict(int) \n    for line in data: \n        for word in line.split(): \n            vocab[' '.join(list(word)) + ' </w>'] += 1\n    return vocab \n\ndef byte_pair_encoding(data, n): \n    \"\"\" \n    Given a list of strings and an integer n, returns a list of n merged pairs \n    of characters found in the vocabulary of the input data. \n    \"\"\"\n    vocab = get_vocab(data) \n    for i in range(n): \n        pairs = get_stats(vocab) \n        best = max(pairs, key=pairs.get) \n        vocab = merge_vocab(best, vocab) \n    return vocab \n\n# Example usage: \ncorpus = '''Tokenization is the process of breaking down \na sequence of text into smaller units called tokens, \nwhich can be words, phrases, or even individual characters. \nTokenization is often the first step in natural languages processing tasks \nsuch as text classification, named entity recognition, and sentiment analysis. \nThe resulting tokens are typically used as input to further processing steps, \nsuch as vectorization, where the tokens are converted \ninto numerical representations for machine learning models to use.'''\ndata_example = corpus.split('.') \n\nn = 230\nbpe_pairs = byte_pair_encoding(data_example, n) \nbpe_pairs\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T16:19:25.113419Z","iopub.execute_input":"2024-01-27T16:19:25.113831Z","iopub.status.idle":"2024-01-27T16:19:25.182516Z","shell.execute_reply.started":"2024-01-27T16:19:25.113799Z","shell.execute_reply":"2024-01-27T16:19:25.181562Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'Tokenization</w>': 2,\n 'is</w>': 2,\n 'the</w>': 3,\n 'process</w>': 1,\n 'of</w>': 2,\n 'breaking</w>': 1,\n 'down</w>': 1,\n 'a</w>': 1,\n 'sequence</w>': 1,\n 'text</w>': 2,\n 'into</w>': 2,\n 'smaller</w>': 1,\n 'units</w>': 1,\n 'called</w>': 1,\n 'tokens,</w>': 1,\n 'which</w>': 1,\n 'can</w>': 1,\n 'be</w>': 1,\n 'words,</w>': 1,\n 'phrases,</w>': 1,\n 'or</w>': 1,\n 'even</w>': 1,\n 'individual</w>': 1,\n 'characters</w>': 1,\n 'often</w>': 1,\n 'first</w>': 1,\n 'step</w>': 1,\n 'in</w>': 1,\n 'natural</w>': 1,\n 'languages</w>': 1,\n 'processing</w>': 2,\n 'tasks</w>': 1,\n 'such</w>': 2,\n 'as</w>': 3,\n 'classification,</w>': 1,\n 'named</w>': 1,\n 'entity</w>': 1,\n 'recognition,</w>': 1,\n 'and</w>': 1,\n 'sentiment</w>': 1,\n 'analysis</w>': 1,\n 'The</w>': 1,\n 'resulting</w>': 1,\n 'tokens</w>': 2,\n 'are</w>': 2,\n 'typically</w>': 1,\n 'used</w>': 1,\n 'input</w>': 1,\n 'to</w>': 2,\n 'further</w>': 1,\n 'steps,</w>': 1,\n 'vectorization,</w>': 1,\n 'where</w>': 1,\n 'converted</w>': 1,\n 'numerical</w>': 1,\n 'representations</w>': 1,\n 'for</w>': 1,\n 'machine</w>': 1,\n 'learning</w>': 1,\n 'models</w>': 1,\n 'use</w>': 1}"},"metadata":{}}]},{"cell_type":"code","source":"data['Cleaned']","metadata":{"execution":{"iopub.status.busy":"2024-01-27T16:19:28.424725Z","iopub.execute_input":"2024-01-27T16:19:28.425400Z","iopub.status.idle":"2024-01-27T16:19:28.433025Z","shell.execute_reply.started":"2024-01-27T16:19:28.425365Z","shell.execute_reply":"2024-01-27T16:19:28.432039Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0          واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح\n1        قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...\n2        قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...\n3        عالی بود همه چه درست و به اندازه و کیفیت خوب ا...\n4                            شیرینی وانیلی فقط یک مدل بود \n                               ...                        \n56695    یک تیکه کم فرستاده بودن و با تماس من در کمترین...\n56696    عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...\n56697    مثل همیشه عالی من چندمین باره سفارش میدم و هرب...\n56698        دلستر استوایی خواسته بودم اما لیمویی فرستادند\n56699    جای مرغ گریل شده ناگت بود به این نمی‌گن چیکن ب...\nName: Cleaned, Length: 56498, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"input_data = data['Cleaned']\n\n# Tokenize the input data using the BPE tokenizer\ntokenized_data = []\nfor sentence in input_data:\n    tokens = []\n    for word in sentence.split():\n        word_bpe = ' '.join(list(word)) + ' </w>'\n        tokens.extend(word_bpe.split())\n    tokenized_data.append(tokens)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T16:19:31.046098Z","iopub.execute_input":"2024-01-27T16:19:31.047020Z","iopub.status.idle":"2024-01-27T16:19:32.913662Z","shell.execute_reply.started":"2024-01-27T16:19:31.046985Z","shell.execute_reply":"2024-01-27T16:19:32.912602Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# CountVectorizor and LR","metadata":{}},{"cell_type":"code","source":"X_train = np.asarray(X_train)\nX_test = np.asarray(X_test)\n\ny_train = np.asarray(y_train)\ny_test = np.asarray(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:17:20.295566Z","iopub.execute_input":"2024-01-30T06:17:20.295938Z","iopub.status.idle":"2024-01-30T06:17:20.302379Z","shell.execute_reply.started":"2024-01-30T06:17:20.295906Z","shell.execute_reply":"2024-01-30T06:17:20.300866Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"classifier = LogisticRegression()\nclassifier.fit(X_train, y_train)\nscore = classifier.score(X_test, y_test)\nprint(\"Accuracy:\", score)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:17:20.303896Z","iopub.execute_input":"2024-01-30T06:17:20.304303Z","iopub.status.idle":"2024-01-30T06:18:57.152275Z","shell.execute_reply.started":"2024-01-30T06:17:20.304268Z","shell.execute_reply":"2024-01-30T06:18:57.148554Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8430088495575221\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy*100)\n\n# Calculate weighted F1 score\nweighted_f1 = f1_score(y_test, y_pred, average='weighted')\nprint(\"Weighted F1 Score:\", weighted_f1*100)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:18:57.158483Z","iopub.execute_input":"2024-01-30T06:18:57.159645Z","iopub.status.idle":"2024-01-30T06:18:58.015642Z","shell.execute_reply.started":"2024-01-30T06:18:57.159594Z","shell.execute_reply":"2024-01-30T06:18:58.011860Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Accuracy: 84.30088495575221\nWeighted F1 Score: 84.29362188037433\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tf_idf Vectorizer","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=2, max_features= 10000)\nX_tfidf_vectorized = vectorizer.fit_transform(data.Cleaned).todense()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:38.182595Z","iopub.execute_input":"2024-01-30T06:44:38.183060Z","iopub.status.idle":"2024-01-30T06:44:42.969410Z","shell.execute_reply.started":"2024-01-30T06:44:38.183005Z","shell.execute_reply":"2024-01-30T06:44:42.968381Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"input_dim = X_tfidf_train.shape\ninput_dim","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:42.971339Z","iopub.execute_input":"2024-01-30T06:44:42.972234Z","iopub.status.idle":"2024-01-30T06:44:42.978847Z","shell.execute_reply.started":"2024-01-30T06:44:42.972193Z","shell.execute_reply":"2024-01-30T06:44:42.977829Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(45198, 10000)"},"metadata":{}}]},{"cell_type":"code","source":"X_tfidf_train = np.asarray(X_tfidf_train)\nX_tfidf_test = np.asarray(X_tfidf_test)\ny_tfidf_train = np.asarray(y_tfidf_train)\ny_tfidf_test = np.asarray(y_tfidf_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:42.980238Z","iopub.execute_input":"2024-01-30T06:44:42.980600Z","iopub.status.idle":"2024-01-30T06:44:42.991068Z","shell.execute_reply.started":"2024-01-30T06:44:42.980566Z","shell.execute_reply":"2024-01-30T06:44:42.990206Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"clf = LogisticRegression()\nclf.fit(X_tfidf_train, y_tfidf_train)\ntfidf_score = clf.score(X_tfidf_test, y_tfidf_test)\nprint(\"Accuracy:\", tfidf_score)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:44:42.992968Z","iopub.execute_input":"2024-01-30T06:44:42.993307Z","iopub.status.idle":"2024-01-30T06:45:29.307025Z","shell.execute_reply.started":"2024-01-30T06:44:42.993281Z","shell.execute_reply":"2024-01-30T06:45:29.299207Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Accuracy: 0.8538938053097345\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}]},{"cell_type":"code","source":"y_tfidf_pred = clf.predict(X_tfidf_test)\n\n# Calculate accuracy\naccuracy_tfidf = accuracy_score(y_tfidf_test, y_tfidf_pred)\nprint(\"Accuracy:\", accuracy_tfidf*100)\n\n# Calculate weighted F1 score\nweighted_f1_tfidf = f1_score(y_tfidf_test, y_tfidf_pred, average='weighted')\nprint(\"Weighted F1 Score:\", weighted_f1_tfidf*100)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:45:29.309336Z","iopub.execute_input":"2024-01-30T06:45:29.310257Z","iopub.status.idle":"2024-01-30T06:45:29.538908Z","shell.execute_reply.started":"2024-01-30T06:45:29.310195Z","shell.execute_reply":"2024-01-30T06:45:29.537399Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Accuracy: 85.38938053097344\nWeighted F1 Score: 85.36112257290006\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tfidf and a basic neural network model","metadata":{}},{"cell_type":"code","source":"nb_classes = 2\nbatch_size = 32\nnb_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:47:57.278035Z","iopub.execute_input":"2024-01-30T06:47:57.278420Z","iopub.status.idle":"2024-01-30T06:47:57.283425Z","shell.execute_reply.started":"2024-01-30T06:47:57.278390Z","shell.execute_reply":"2024-01-30T06:47:57.282258Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"y_tfidf_train_cat = to_categorical(y_tfidf_train)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:47:58.959495Z","iopub.execute_input":"2024-01-30T06:47:58.959883Z","iopub.status.idle":"2024-01-30T06:47:58.965926Z","shell.execute_reply.started":"2024-01-30T06:47:58.959852Z","shell.execute_reply":"2024-01-30T06:47:58.964924Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(1000,input_shape= (input_dim[1],)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(500))\n\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(50))\n\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:48:00.133332Z","iopub.execute_input":"2024-01-30T06:48:00.133737Z","iopub.status.idle":"2024-01-30T06:48:01.251858Z","shell.execute_reply.started":"2024-01-30T06:48:00.133705Z","shell.execute_reply":"2024-01-30T06:48:01.250973Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:48:01.340166Z","iopub.execute_input":"2024-01-30T06:48:01.340548Z","iopub.status.idle":"2024-01-30T06:48:01.345373Z","shell.execute_reply.started":"2024-01-30T06:48:01.340520Z","shell.execute_reply":"2024-01-30T06:48:01.344222Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.fit(X_tfidf_train, y_tfidf_train_cat, batch_size=batch_size, epochs=nb_epochs,verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:48:01.998800Z","iopub.execute_input":"2024-01-30T06:48:01.999200Z","iopub.status.idle":"2024-01-30T06:59:08.008347Z","shell.execute_reply.started":"2024-01-30T06:48:01.999169Z","shell.execute_reply":"2024-01-30T06:59:08.007190Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n1413/1413 - 66s - loss: 0.3780 - 66s/epoch - 47ms/step\nEpoch 2/10\n1413/1413 - 66s - loss: 0.2996 - 66s/epoch - 46ms/step\nEpoch 3/10\n1413/1413 - 66s - loss: 0.2333 - 66s/epoch - 46ms/step\nEpoch 4/10\n1413/1413 - 66s - loss: 0.1526 - 66s/epoch - 46ms/step\nEpoch 5/10\n1413/1413 - 66s - loss: 0.0912 - 66s/epoch - 46ms/step\nEpoch 6/10\n1413/1413 - 65s - loss: 0.0635 - 65s/epoch - 46ms/step\nEpoch 7/10\n1413/1413 - 66s - loss: 0.0462 - 66s/epoch - 47ms/step\nEpoch 8/10\n1413/1413 - 68s - loss: 0.0359 - 68s/epoch - 48ms/step\nEpoch 9/10\n1413/1413 - 67s - loss: 0.0322 - 67s/epoch - 47ms/step\nEpoch 10/10\n1413/1413 - 66s - loss: 0.0291 - 66s/epoch - 46ms/step\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7f7f80c88580>"},"metadata":{}}]},{"cell_type":"code","source":"y_test_pred = model.predict(X_tfidf_test)\ny_test_predclass = np.argmax(y_test_pred, axis=1)\ny_trian_pred = model.predict(X_tfidf_train)\ny_train_predclass = np.argmax(y_trian_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:08.010772Z","iopub.execute_input":"2024-01-30T06:59:08.011595Z","iopub.status.idle":"2024-01-30T06:59:29.313979Z","shell.execute_reply.started":"2024-01-30T06:59:08.011544Z","shell.execute_reply":"2024-01-30T06:59:29.312789Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"354/354 [==============================] - 3s 7ms/step\n1413/1413 [==============================] - 11s 7ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print (\"nDeep Neural Network - Test accuracy:\",(round(accuracy_score(y_tfidf_test, y_test_predclass),4)*100))\nprint (\"nDeep Neural Network - Train accuracy:\",(round(accuracy_score(y_tfidf_train, y_train_predclass),4)*100))","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:29.318072Z","iopub.execute_input":"2024-01-30T06:59:29.318524Z","iopub.status.idle":"2024-01-30T06:59:29.333533Z","shell.execute_reply.started":"2024-01-30T06:59:29.318485Z","shell.execute_reply":"2024-01-30T06:59:29.332495Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"nDeep Neural Network - Test accuracy: 82.67\nnDeep Neural Network - Train accuracy: 99.71\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing set predictions and F1 score\ny_test_pred = model.predict(X_tfidf_test)\ny_test_predclass = np.argmax(y_test_pred, axis=1)\ntest_f1 = f1_score(y_tfidf_test, y_test_predclass, average='weighted')\nprint(\"Deep Neural Network - Test F1 score:\", round(test_f1, 4) * 100)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:29.335867Z","iopub.execute_input":"2024-01-30T06:59:29.336545Z","iopub.status.idle":"2024-01-30T06:59:33.556931Z","shell.execute_reply.started":"2024-01-30T06:59:29.336514Z","shell.execute_reply":"2024-01-30T06:59:33.555839Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"354/354 [==============================] - 3s 7ms/step\nDeep Neural Network - Test F1 score: 82.67\n","output_type":"stream"}]},{"cell_type":"code","source":"def _multiple_replace(mapping, text):\n    pattern = \"|\".join(map(re.escape, mapping.keys()))\n    return re.sub(pattern, lambda m: mapping[m.group()], str(text))\n\ndef convert_fa_numbers(input_str):\n    mapping = {\n        '۰': '0',\n        '۱': '1',\n        '۲': '2',\n        '۳': '3',\n        '۴': '4',\n        '۵': '5',\n        '۶': '6',\n        '۷': '7',\n        '۸': '8',\n        '۹': '9',\n        '.': '.',\n    }\n    return _multiple_replace(mapping, input_str)\n\n\ndef convert_ar_characters(input_str):\n    \"\"\"\n    Converts Arabic chars to related Persian unicode char\n    :param input_str: String contains Arabic chars\n    :return: New str with converted arabic chars\n    \"\"\"\n    mapping = {\n        'ك': 'ک',\n        'ى': 'ی',\n        'ي': 'ی',\n        'ئ':'ی',\n        'إ':'ا',\n        'أ':'ا',\n        'ة':'ه',\n        'ؤ':'و'\n    }\n    return _multiple_replace(mapping, input_str)\n\n\ndef preprocess(text):\n    extractor = URLExtract()\n    for url in extractor.gen_urls(text):\n        text = text.replace(url,'<URL>')\n    emj = emojis.get(text)\n    for i in emj:\n        if i in text:\n            text = text.replace(i,'<emoji>')\n    text = convert_fa_numbers(text)\n    text = convert_ar_characters(text)\n    # regex to detect and replace all smilies in the text with <smiley>\n    text = re.sub(r\"(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\)|:\\s?D|8-\\)|:\\s?\\||;\\s?\\)|:-\\*|:-\\||:-\\(|:\\s?P|:-P|:-p|:-b|:-O|:-o|:-0|:-\\@|:\\$|:-\\^|:-&|:-\\*|:-\\+|:-\\~|:-\\`|:-\\>|:-\\<|:-\\}|:-\\{|\\[:\\s?\\]|\\[:\\s?\\]|:\\s?\\]|:\\s?\\[|:\\s?\\}|:\\s?\\{)\",'<smiley>',text)\n    text = text.lower() # we lowercase here to prevent changes in the URLs and smilies\n    text = text.strip()\n    text = re.sub(r'[<>#.:()\"\\'!?؟،,@$%^&*_+\\[\\]/]', ' ', text)\n    text = re.sub(r'[\\s]{2,}', ' ', text)\n    text = re.sub(r'(\\w)\\1{2,}', r'\\1',text)\n    if re.search(r'[\\u0600-\\u06FF]', text):\n        return(text)\n    else:\n        return 'None'","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:33.558944Z","iopub.execute_input":"2024-01-30T06:59:33.559377Z","iopub.status.idle":"2024-01-30T06:59:33.573584Z","shell.execute_reply.started":"2024-01-30T06:59:33.559339Z","shell.execute_reply":"2024-01-30T06:59:33.572390Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X_pred = vectorizer.transform([preprocess('دیگه از این رستوران سفارش نمیدم')]).todense()\nmodel.predict(X_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:33.575049Z","iopub.execute_input":"2024-01-30T06:59:33.575388Z","iopub.status.idle":"2024-01-30T06:59:33.831127Z","shell.execute_reply.started":"2024-01-30T06:59:33.575360Z","shell.execute_reply":"2024-01-30T06:59:33.830045Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 71ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"array([[0.37234625, 0.6276537 ]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"X_pred = vectorizer.transform([preprocess('بازم از این رستوران سفارش میدم')]).todense()\nmodel.predict(X_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:33.832514Z","iopub.execute_input":"2024-01-30T06:59:33.832860Z","iopub.status.idle":"2024-01-30T06:59:33.963482Z","shell.execute_reply.started":"2024-01-30T06:59:33.832832Z","shell.execute_reply":"2024-01-30T06:59:33.962426Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 28ms/step\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[0.9976605 , 0.00233948]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"X_pred = vectorizer.transform([preprocess('خیلی خوب بود!')]).todense()\nmodel.predict(X_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T06:59:33.965215Z","iopub.execute_input":"2024-01-30T06:59:33.965686Z","iopub.status.idle":"2024-01-30T06:59:34.094687Z","shell.execute_reply.started":"2024-01-30T06:59:33.965647Z","shell.execute_reply":"2024-01-30T06:59:34.093567Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 32ms/step\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[9.9997318e-01, 2.6834792e-05]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Word embedings and LSTM","metadata":{}},{"cell_type":"code","source":"data.Cleaned","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:16:50.381836Z","iopub.execute_input":"2024-01-19T19:16:50.382231Z","iopub.status.idle":"2024-01-19T19:16:50.391270Z","shell.execute_reply.started":"2024-01-19T19:16:50.382200Z","shell.execute_reply":"2024-01-19T19:16:50.390254Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0          واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح\n1        قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...\n2        قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...\n3        عالی بود همه چه درست و به اندازه و کیفیت خوب ا...\n4                            شیرینی وانیلی فقط یک مدل بود \n                               ...                        \n56695    یک تیکه کم فرستاده بودن و با تماس من در کمترین...\n56696    عالی بود همه چیز ممنونم پیک هم خیلی مرتب و به ...\n56697    مثل همیشه عالی من چندمین باره سفارش میدم و هرب...\n56698        دلستر استوایی خواسته بودم اما لیمویی فرستادند\n56699    جای مرغ گریل شده ناگت بود به این نمی‌گن چیکن ب...\nName: Cleaned, Length: 56498, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X = data['Cleaned']\ntokenizer = Tokenizer(num_words=20000)\ntokenizer.fit_on_texts(X)\nX=tokenizer.texts_to_sequences(X)\nX=pad_sequences(X,maxlen=100)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:16:51.338456Z","iopub.execute_input":"2024-01-19T19:16:51.338886Z","iopub.status.idle":"2024-01-19T19:16:55.662614Z","shell.execute_reply.started":"2024-01-19T19:16:51.338853Z","shell.execute_reply":"2024-01-19T19:16:55.661507Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:16:55.664929Z","iopub.execute_input":"2024-01-19T19:16:55.665328Z","iopub.status.idle":"2024-01-19T19:16:55.672203Z","shell.execute_reply.started":"2024-01-19T19:16:55.665290Z","shell.execute_reply":"2024-01-19T19:16:55.671084Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(56498, 100)"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42) ","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:23:57.037615Z","iopub.execute_input":"2024-01-19T19:23:57.038652Z","iopub.status.idle":"2024-01-19T19:23:57.057559Z","shell.execute_reply.started":"2024-01-19T19:23:57.038615Z","shell.execute_reply":"2024-01-19T19:23:57.056425Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"y_train_cat = to_categorical(y_train, num_classes=2)\ny_test_cat = to_categorical(y_test, num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:23:57.209682Z","iopub.execute_input":"2024-01-19T19:23:57.210181Z","iopub.status.idle":"2024-01-19T19:23:57.217443Z","shell.execute_reply.started":"2024-01-19T19:23:57.210140Z","shell.execute_reply":"2024-01-19T19:23:57.216396Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"rnn_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=20000, output_dim=32, input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n    tf.keras.layers.Bidirectional(layers.LSTM(128)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(2, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:23:57.708347Z","iopub.execute_input":"2024-01-19T19:23:57.708767Z","iopub.status.idle":"2024-01-19T19:23:58.821335Z","shell.execute_reply.started":"2024-01-19T19:23:57.708734Z","shell.execute_reply":"2024-01-19T19:23:58.820505Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"rnn_model.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:23:58.823146Z","iopub.execute_input":"2024-01-19T19:23:58.823771Z","iopub.status.idle":"2024-01-19T19:23:58.836471Z","shell.execute_reply.started":"2024-01-19T19:23:58.823732Z","shell.execute_reply":"2024-01-19T19:23:58.835533Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"rnn_model.fit(X_train, y_train_cat, epochs=3,\n              validation_data=(X_test, y_test_cat),\n              validation_steps=30)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:24:00.000553Z","iopub.execute_input":"2024-01-19T19:24:00.001254Z","iopub.status.idle":"2024-01-19T19:26:25.135815Z","shell.execute_reply.started":"2024-01-19T19:24:00.001220Z","shell.execute_reply":"2024-01-19T19:26:25.134693Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/3\n1413/1413 [==============================] - 75s 48ms/step - loss: 0.4216 - accuracy: 0.8051 - val_loss: 0.3541 - val_accuracy: 0.8501\nEpoch 2/3\n1413/1413 [==============================] - 35s 25ms/step - loss: 0.3253 - accuracy: 0.8655 - val_loss: 0.3521 - val_accuracy: 0.8528\nEpoch 3/3\n1413/1413 [==============================] - 34s 24ms/step - loss: 0.3017 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8503\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c26d0e6d9c0>"},"metadata":{}}]},{"cell_type":"code","source":"y_test_pred = rnn_model.predict(X_test)\ny_test_predclass = np.argmax(y_test_pred, axis=1)\ny_trian_pred = rnn_model.predict(X_train)\ny_train_predclass = np.argmax(y_trian_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:26:25.137612Z","iopub.execute_input":"2024-01-19T19:26:25.137962Z","iopub.status.idle":"2024-01-19T19:26:41.664006Z","shell.execute_reply.started":"2024-01-19T19:26:25.137931Z","shell.execute_reply":"2024-01-19T19:26:41.663060Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"354/354 [==============================] - 4s 8ms/step\n1413/1413 [==============================] - 11s 8ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report\nprint (\"nDeep Neural Network - Test accuracy:\",(round(accuracy_score(y_test, y_test_predclass),4)*100))\nprint (\"nDeep Neural Network - Train accuracy:\",(round(accuracy_score(y_train, y_train_predclass),4)*100))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:26:41.665276Z","iopub.execute_input":"2024-01-19T19:26:41.665642Z","iopub.status.idle":"2024-01-19T19:26:41.679333Z","shell.execute_reply.started":"2024-01-19T19:26:41.665611Z","shell.execute_reply":"2024-01-19T19:26:41.678136Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"nDeep Neural Network - Test accuracy: 85.03\nnDeep Neural Network - Train accuracy: 89.64999999999999\n","output_type":"stream"}]},{"cell_type":"code","source":"test_f1 = f1_score(y_test, y_test_predclass, average='weighted')\nprint(\"Deep Neural Network - Test F1 score:\", round(test_f1, 4) * 100)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:27:47.511110Z","iopub.execute_input":"2024-01-19T19:27:47.512016Z","iopub.status.idle":"2024-01-19T19:27:47.526466Z","shell.execute_reply.started":"2024-01-19T19:27:47.511962Z","shell.execute_reply":"2024-01-19T19:27:47.525175Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Deep Neural Network - Test F1 score: 85.0\n","output_type":"stream"}]},{"cell_type":"code","source":"X_pred=tokenizer.texts_to_sequences(['غذا خیلی خوب بود'])\nX_pred=pad_sequences(X_pred,maxlen=100)\n\nrnn_model.predict(X_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T19:28:01.987718Z","iopub.execute_input":"2024-01-19T19:28:01.988937Z","iopub.status.idle":"2024-01-19T19:28:02.071877Z","shell.execute_reply.started":"2024-01-19T19:28:01.988883Z","shell.execute_reply":"2024-01-19T19:28:02.070917Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 29ms/step\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"array([[0.90641296, 0.09358707]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Byte-Pair encoding tokenizer and LSTM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\nembedding_dim = 100\nhidden_dim = 128\nnum_classes = 2\nbatch_size = 32\nnum_epochs = 30\nlearning_rate = 0.01\n\n\n# Convert tokens to numerical sequences\nword_to_index = {word: idx for idx, word in enumerate(bpe_pairs.keys())}\nword_to_index['و'] = len(word_to_index)\n\nnumerical_sequences = [[word_to_index.get(token, 0) for token in sentence] for sentence in tokenized_data]\n\n# Pad sequences to ensure equal length\nmax_sequence_length = 50  # You can adjust this based on your model's requirements\npadded_sequences = pad_sequences(numerical_sequences, maxlen=max_sequence_length, padding='post')\n\n# Example LSTM model\nembedding_dim = 32\nlstm_units = 64\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=len(bpe_pairs), output_dim=embedding_dim, input_length=max_sequence_length))\nmodel.add(LSTM(units=lstm_units))\nmodel.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model (you may need to adjust the loss function and optimizer based on your task)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Now, you can train your model using padded_sequences as input and your sentiment labels\nmodel.fit(padded_sequences, labels, epochs=num_epochs, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T16:19:52.590448Z","iopub.execute_input":"2024-01-27T16:19:52.591412Z","iopub.status.idle":"2024-01-27T16:24:26.061970Z","shell.execute_reply.started":"2024-01-27T16:19:52.591381Z","shell.execute_reply":"2024-01-27T16:24:26.060994Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1766/1766 [==============================] - 12s 5ms/step - loss: 0.6932 - accuracy: 0.5046\nEpoch 2/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6930 - accuracy: 0.5064\nEpoch 3/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6926 - accuracy: 0.5152\nEpoch 4/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6920 - accuracy: 0.5212\nEpoch 5/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6908 - accuracy: 0.5276\nEpoch 6/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6900 - accuracy: 0.5321\nEpoch 7/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6889 - accuracy: 0.5388\nEpoch 8/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6851 - accuracy: 0.5485\nEpoch 9/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6838 - accuracy: 0.5532\nEpoch 10/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6828 - accuracy: 0.5575\nEpoch 11/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6806 - accuracy: 0.5625\nEpoch 12/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6778 - accuracy: 0.5673\nEpoch 13/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6771 - accuracy: 0.5696\nEpoch 14/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6765 - accuracy: 0.5711\nEpoch 15/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6756 - accuracy: 0.5721\nEpoch 16/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6751 - accuracy: 0.5722\nEpoch 17/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6747 - accuracy: 0.5743\nEpoch 18/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6739 - accuracy: 0.5762\nEpoch 19/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6735 - accuracy: 0.5744\nEpoch 20/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6731 - accuracy: 0.5739\nEpoch 21/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6722 - accuracy: 0.5781\nEpoch 22/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6715 - accuracy: 0.5795\nEpoch 23/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6710 - accuracy: 0.5800\nEpoch 24/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6704 - accuracy: 0.5797\nEpoch 25/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6700 - accuracy: 0.5804\nEpoch 26/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6692 - accuracy: 0.5818\nEpoch 27/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6690 - accuracy: 0.5833\nEpoch 28/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6685 - accuracy: 0.5834\nEpoch 29/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6687 - accuracy: 0.5835\nEpoch 30/30\n1766/1766 [==============================] - 9s 5ms/step - loss: 0.6673 - accuracy: 0.5844\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7d2ce4935600>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# Predictions for the test set\ny_test_pred = model.predict(padded_sequences)\ny_test_predclass = np.round(y_test_pred).flatten().astype(int)\n\n# Predictions for the train set\ny_train_pred = model.predict(padded_sequences)\ny_train_predclass = np.round(y_train_pred).flatten().astype(int)\n\n# Evaluate the model\ntest_accuracy = accuracy_score(labels, y_test_predclass)\ntrain_accuracy = accuracy_score(labels, y_train_predclass)\ntest_f1 = f1_score(labels, y_test_predclass, average='weighted')\n\nprint(\"Deep Neural Network - Test accuracy:\", round(test_accuracy, 4) * 100)\nprint(\"Deep Neural Network - Train accuracy:\", round(train_accuracy, 4) * 100)\nprint(\"Deep Neural Network - Test F1 score:\", round(test_f1, 4) * 100)\n\n# Tokenize a new input and make a prediction\nnew_input = ['غذا خیلی خوب بود']\nnumerical_sequences_pred = [[word_to_index.get(token, 0) for token in sentence.split()] for sentence in new_input]\npadded_sequences_pred = pad_sequences(numerical_sequences_pred, maxlen=max_sequence_length, padding='post')\n\nprediction = model.predict(padded_sequences_pred)\nprint(\"Prediction:\", prediction)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:45:33.436128Z","iopub.execute_input":"2024-01-26T10:45:33.437021Z","iopub.status.idle":"2024-01-26T10:45:42.905790Z","shell.execute_reply.started":"2024-01-26T10:45:33.436988Z","shell.execute_reply":"2024-01-26T10:45:42.904870Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"1766/1766 [==============================] - 4s 2ms/step\n1766/1766 [==============================] - 4s 2ms/step\nDeep Neural Network - Test accuracy: 58.96\nDeep Neural Network - Train accuracy: 58.96\nDeep Neural Network - Test F1 score: 58.040000000000006\n1/1 [==============================] - 0s 18ms/step\nPrediction: [[0.5497471]]\n","output_type":"stream"}]}]}